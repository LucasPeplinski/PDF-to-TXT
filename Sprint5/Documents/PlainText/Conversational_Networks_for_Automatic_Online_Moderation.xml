<article>
	<preamble>Conversational_Networks_for_Automatic_Online_Moderation</preamble>
    <titre>conversational networks for automatic online moderation</titre>
    <auteur> etienne.papegnies@univ-avignon.fr </auteur>
	<abstract>--moderation of user-generated content in an online community is a challenge that has great socio-economic ramifi- cations. however, the costs incurred by delegating this paper to human agents are high. for this reason, an automatic system able to detect abuse in user-generated content is of great interest. there are a number of ways to tackle this problem, but the most commonly seen in practice are word filtering or regular expression matching. the main limitations are their vulnerability to intentional obfuscation on the part of the users, and their context-insensitive nature. moreover, they are language dependent and may require appropriate corpora for training. in this paper, we propose a system for automatic abuse detection that completely disregards message content. we first extract a conversational network from raw chat logs and characterize it through topological measures. we then use these as features to train a classifier on our abuse detection task. we thoroughly assess our system on a dataset of user comments originating from a french massively multiplayer online game. we identify the most appropriate network extraction parameters and discuss the discriminative power of our features, relatively to their topological and temporal nature. our method reaches an f-measure of 83.89 when using the full feature set, improving on existing approaches. with a selection of the most discriminative features, we dramatically cut computing time while retaining the most of the performance (82.65). index terms--classification algorithms, information retrieval, network theory (graphs), social computing, text analysis. i. </abstract>
	<introduction> online communities have acquired an indisputable importance in today's society. from modest beginnings as places to trade ideas around specific topics, they have grown into important focuses of attention for companies to adver- tize products or governments interested in monitoring public discourse. they also have a strong social effect, by heavily impacting public and interpersonal communications. however, the internet grants a degree of anonymity, and because of that, online communities are often confronted with users exhibiting abusive behaviors. the notion of abuse varies depending on the community, but there is almost always a common core of rules stating that users should not personally attack others or discriminate them based on race, religion, or sexual orientation. it can also include more manuscript received april 16, 2018; revised september 25, 2018; accepted december 6, 2018. date of publication january 29, 2019; date of current version february 12, 2019. this work was supported in part by provence- alpes-cte-d'azur region, france and in part by nectar de code company. (corresponding author: etienne papegnies.) e. papegnies is with the laboratoire informatique d'avignon, avignon university, 84911 avignon, france, and also with nectar de code, 13570 barbentane, france (e-mail: etienne.papegnies@univ-avignon.fr). v. labatut, r. dufour, and g. linares are with the laboratoire informatique d'avignon, avignon university, 84911 avignon, france. digital object identifier 10.1109/tcss.2018.2887240 community-specific aspects, e.g., not posting advertisement or external urls. for community maintainers, it is often necessary to act on abusive behaviors: if they do not, abusive users can poison the community, make important commu- nity members leave, and, in some countries, trigger legal issues [1], [2]. when users break the community rules, sanctions can then be applied. this process, called moderation, is mainly done by humans. since this manual work is expensive, companies have a vested interest in automating the process. in this paper, we consider the classification problem consisting in automatically determining if a user message is abusive or not. this task is at the core of automated moderation, and it is difficult for several reasons. first, the amount of noise in the content (typos, grammatical errors, uncommon abbreviations, out-of-vocabulary words...) of messages posted on the internet is usually quite high. furthermore, while some of this noise is unwittingly produced by fast typing or poor language skills, a good part of it is voluntarily introduced as a means to defeat automated badword checks, e.g. "pls d1e you f8 ck". then, even with a noiseless message, it is sometimes necessary to perform advanced natural language analysis to detect abuse in a message. here is a fictional example of a message containing no obvious indicators of abuse such as straight insults, while still being very abusive indeed: "would you like to meet your maker? i can arrange that". finally, even advanced natural language processing approaches may not be able to detect abuse from a message only without looking at its context. this context can take various forms. for instance, in the case of a "yo mama joke", it is the continuation of the conversation. but it can also include external knowledge, which makes it harder to handle. consider the following exchange, for example: a: "they've been discriminated against enough. six millions of them were killed during the holocaust." -- b: "that didn't actually happen". the message from b has no abuse markers at all until one considers both the messages that came before and historical knowledge. to address these issues, we propose, as our main con- tribution in this paper, an approach that completely ignores the content of the messages and models conversations under the form of conversational graphs. by doing so, we aim to create a model that is not vulnerable to text-based obfuscation. we characterize these graphs through a number of topological measures which are then used as features, in order to train and test a classifier. our second contribution is to apply our method to a corpus of chat logs originating from the community of the french massively multiplayer online game spaceorigin.1 1https://play.spaceorigin.fr/ 2329-924x  2019 ieee. personal use is permitted, but republication/redistribution requires ieee permission. see http://www.ieee.org/publications_standards/publications/rights/index.html for more information. papegnies et al.: conversational networks for automatic online moderation 39 our third contribution is to investigate the relative importance of the classification features, as well as the parameters of the graph extraction process, with regard to our classification task--the detection of abusive messages. this paper is a significantly extended version of our prelimi- nary work started in [3]. in comparison, we propose and exper- iment with several variations of our network extraction method and vastly expand the array of features that we consider. we also adapt our approach to greatly increase the efficiency of our system with regard to necessary computational resources and make it more versatile to possible use cases. the rest of this paper is organized as follows. in section ii, we review related work on abuse detection and previous approaches dedicated to network extraction from various types of conversation logs. we describe the methods used throughout our pipeline in section iii, including the approach proposed to extract conversational networks, and the topological fea- tures that we compute to characterize them. in section iv, we present our dataset, as well as the overall experimental setup for the classification task. we then provide a discussion and a qualitative study of the performance of our approach, with a focus on the contributions of the considered features. because some of them are computed from information that is not yet available at the instant some messages are posted, we also examine the performances of the system-based only on information available at the time (i.e., as a prediction task). finally, we summarize our contributions in section v and present some perspectives for this paper. ii. related work in this section, we first review general approaches related to the problem of abuse detection (section ii-a), and then focus on techniques that have been previously used to extract graph- based representations of conversation logs (section ii-b). a. abuse detection one can distinguish two main categories of works related to abuse detection: those using the content of the targeted messages only and those focusing on their context (user metadata, content of surrounding messages...). some hybrid works also propose to combine both categories. 1) content-based approaches: the work initiated by spertus in [4] constitutes a first attempt to create a classifier for hostile messages. abusive messages often contain hostility, so this task is related to ours. however, the notion of abuse is more general, as it can take a nonhostile form. spertus uses static rules to extract linguistic markers for each message: imperative statement, profanity, condescension, insult, politeness, and praise. these are then used as features in a binary classifier. this approach obtains good results, except in specific cases like hostility through sarcasm. however, manually defining all the linguistic rules related to an abusive message is a severe limitation and appears impossible, in practice. also, its application to another language would require to transpose it to other grammar rules and idioms. chen et al. [5] seek to detect offensive language in social media so that it can be filtered out to protect adolescents. like before, this task is more specific than ours, as using offensive language is just one type of abuse. chen et al. [5] developed a system that uses lexical and syntactical features as well as user modeling, to predict the offensiveness value of a comment. they note that the presence of a word tagged as offensive in a message is not a definite indication that the message itself is offensive. for instance, while "you are stupid" is clearly offensive, "this is stupid xd" is not. they further show that lack of context can be somewhat mitigated by looking at word n-grams instead of unigrams (i.e., single words). the method relies on manually constituted language-dependent resources though, such as a lexicon of offensive terms, which also makes it difficult to transpose to another language. dinakar et al. [6] use t f --id f features, a static list of badwords, and of widely used sentences containing verbal abuse, to detect cyberbullying in youtube comments. bullying is mainly characterized by its persistent and repetitive nature, and it can, therefore, be considered as a very specific type of abuse. like before, the proposed model shows good results except when sarcasm is used. it is worth noting that sarcasm can be considered as a form of natural language obfuscation that is especially hard to detect in written communications, because of the lack of inflection clues. chavan and shylaja [7] review machine learning (ml) approaches to detect cyberbullying in online social networks. they show that pronoun occurrences, usually neglected in text classification, are very important to detect online bullying. they use skip-gram features to mitigate the sentence-level context issues by taking into account distant words. these new features allow them to boost the accuracy of a classifier detecting bullying by 4% points. the approach is, however, still vulnerable to involuntary misspellings and word-level obfuscation. it uses a language-dependent list of badwords during preprocessing. in their recent article, mubarak et al. [8] work on the detection of offensive language in arabic media, by intro- ducing the interesting possibility of dynamically generating and expanding a list of bad words. they extract a corpus of tweets that is divided into two classes (obscene/not obscene) based on static rules. then, they perform a log odds ratio analysis to detect the words favoring documents from the obscene class. such an approach could be very useful in an online classification setting, but inherently requires a dataset where the number of samples in the obscene class is large. still, they show that a list of words dynamically generated using that method contains 60% of new obscene words, and the process can be iterated over. relatively to our problem of interest, the main limitation of this paper is its focus on obscene words, which are just one specific type of abuse. razavi et al. [9] focus on a wider spectrum of types of abuse than the previously cited works, which they call inflammatory comments. it ranges from impoliteness to insult, and includes rants and taunts. to detect them, they stack three levels of naive bayes classifier variants, fed with features related to the presence, frequency, and strength of offensive expressions. these are computed based on a manually constituted lexicon of offensive expressions and insults, which makes the method relatively corpus-specific. the resulting system shows high 40 ieee transactions on computational social systems, vol. 6, no. 1, february 2019 precision and has the useful characteristics of being updatable online. it is, however, vulnerable to the text-based obfuscation techniques we have previously mentioned. with recent developments in gpu architecture and hardware availability, more computationally expansive techniques have been used. djuric et al. [10] detect hate speech in twitter data. they adopt a two-step approach consisting in first learning a low-dimensional representation of the tweets, and then applying a classifier to discriminate them based on this representation. they note that jointly using message- and word embeddings instead of simple bag-of-words boosts the performance. park and fung [11] also work on tweets using neural networks, but they focus only on sexism- and racism- related cases. they propose a two-step framework consisting in first training a convolutional neural network (cnn) to identify the absence/presence of abuse, and then performing a simple logistic regression to further discriminate between sexism and racism. both of these approaches are inherently portable, however, they require a lot of data. pavlopoulos et al. [12] develop an automatic moderation system for comments posted by users on websites. it is based on a recurrent neural network operating on word embeddings, with an attention mechanism. they apply it to two large corpus extracted from a greek sports website and the english wikipedia. the proposed system outperforms cnn and other more mainstream classifiers. however, it is worth noticing that these tasks are slightly different, as the the greek corpus is annotated for general moderation, whereas the english one focuses on personal attacks. it is worth noting that all these ml-based approaches perform better when a large dataset is available for train- ing. however, text-based approaches are usually language dependent, which means that models have to be trained on a dataset of the specific language. this is usually not an issue when classifying english messages because of the wealth of publicly available data but is problematic in our case, since our messages come from low-resource language communities. content-based text classification usually makes for a good baseline. however, such methods have severe limitations. first, abuse can be spread over a succession of messages. some messages can even reference a shared history between two users. second, it is very common for users to voluntarily obfuscate message content to work around badwords detection. indeed, abusers can bypass automatic systems by making the abusive content difficult to detect: for instance, they can intentionally modify the spelling of a forbidden word. hosseini et al. [13] demonstrate such an attack against the google perspective api.adversarial attacks based on word-level obfuscation are nothing new, and approaches exist to counter them. for instance, lee and ng [14] experiment with spam de-obfuscation using a hidden markov model that incorporates lexical information. such an approach yields good results for de-obfuscation, but it is computationally expen- sive and requires a dataset of obfuscated words for training. more recently, rojas-galeano [15] describes a more compact approach based on a dynamic programing sequence alignment 2https://www.perspectiveapi.com algorithm. it has a different set of limitations, the main one being that it does not allow for one character to be used as an obfuscated version of several distinct original characters (it uses a one-to-one character mapping). 2) context-based approaches: because the reactions of other users to an abuse case are completely beyond the control of the abuser, some works consider the content of messages around the targeted message, instead of the content of the targeted message only. for instance, yin et al. [16] use features derived from the sentences neighboring a given message to detect harassment on the web. harassment implies repetition and can be con- sidered as a specific type of abuse. their goal is to spot conversations going off-topic and use that as an indicator. their combined content/context approach shows good results when used against multiparticipant chat logs. they also note that sentiment features seem to constitute mostly noise due to the high misspelling rate. this lack of discriminative power from sentiment features is something we have also noticed while experimenting with content-based techniques on our data in [17]. cheng et al. [18] do not try to perform automatic modera- tion. instead, they conduct a comprehensive study of antisocial behavior in online discussion communities, and use its results to build user behavior models. we include this paper in our review, because it provides some insight into the devolution of abusive users over time in a community, regarding both the quality of their contributions and their reactions toward other members of the community. a critical result of this analysis is that instances of antisocial messages usually generate a bigger response from the community, compared to normal messages. in our own work, we build upon this observa- tion and compare classification performances obtained when considering or ignoring messages published right after the classified message. balci and salah [19] take advantage of user features to detect abuse in the community of an online game. these features include information such as gender, number of friends, financial investment, avatars, and general rankings. the goal is to help human moderators dealing with abuse reports, and the approach yields sufficiently good results to achieve this. one important difference with our work is that in our case, the user data necessary to replicate this approach are not available. as a practical consideration the availability of that data will always depend on the type of the community. in [17], we tackle the same problem as in this paper, i.e., detect abuse in chat messages in the context of an online game. however, unlike the method proposed presently, we use a wide array of language features (bag-of-words, t f -id f scores, sentiment scores...) as well as context features derived from the language models of other users. we also experiment with several advanced preprocessing approaches. this method allows us to reach a performance of 72.1% in terms of f-measure on our abusive message detection task. of all the approaches of the literature described in this section, [17] as well as balci and salah's [19] aim at solving the same problem as us. the others focus on tasks which are related to abuse detection, but still different, and generally papegnies et al.: conversational networks for automatic online moderation 41 more specific, e.g., insult or cyberbullying detection. the work of balci & salah differs from ours in the way they solve the problem, as they focus on the users' profiles and behaviors: these data are not available in our case, so we only use the published messages. our previous work [17] is completely based on the textual content of the messages, whereas the one presented here ignores it, and relies only on a graph-based modeling of the conversation, which is com- pletely new in this context. another important methodological difference with the literature is that almost all content-based methods rely on manually constituted linguistic resources, which makes them difficult to transpose to another context (different languages or online community). by comparison, our present approach is completely language independent, as it does not use the textual content (apart from user names). the third difference is that almost all methods from the literature consider messages independently, when we use sequences of messages forming conversations. finally, we use a classic classifier to determine if a message is abusive, which means that our approach requires much less training data than the deep learning methods that we mentioned earlier. b. network extraction from conversation logs although a major part of the methods proposed to address the abuse detection problem focus on the content of the exchanged messages, it appears that a user with previous expo- sure to automatic moderation techniques can easily circumvent them [13]. to avoid this issue, a solution would be not to focus on the textual content, but rather on the interactions between the users through these messages. for instance, the number of respondents to a given message appears frequently as a classification feature in the literature, e.g., as in [18]. but graphs constitute a more natural paradigm to model such relational information, under the form of so-called conversa- tional networks, which represent the flow of the conversation between users. such networks have the advantage of including the mentioned feature (number of respondents), but also much more information regarding the way users interact. we adopted this approach in [3], which is the first attempt at using such graph-based conversation models to solve a general abuse detection problem. our present work is an extension of this method, essentially on two aspects: we experiment with several variations of our graph-extraction process, and we consider much more graph-based features. this section reviews methods proposed in the literature for the extraction of conversational networks. we do not narrow it to the abuse detection context, as [3] would be the only one concerned. even so, there are not many works dealing with the extraction of conversational networks. this may be due to the fact that the task can be far from trivial, depending on the nature of the available raw data: it is much harder for chat logs than for structured messages board or web forums, for instance. in a multiparticipant chat log it is frequent to see multiple disjointed conversations overlapping. there is no fixed topic although some chatrooms have a general purpose. there is also no built-in mechanism to specify the message someone is responding to. finally, in most internet relay chat (irc) chat logs, there is no enforcement mechanism to ensure that users have only one nickname. mutton [20] proposes a strategy to extract such a network from irc chat logs. the goal is to build a tool to visualize user interactions in an irc chat room over time. the author uses a simple set of rules based on direct referencing (i.e., when a user addresses another one by using his nickname), as well as temporal proximity and temporal density of the messages. in our own work, we adapt and expend on some of these rules, whereas certain cannot be applied. specifically, while in a regular irc channel timestamps are indeed useful to determine intended recipients of a message, in our case they are basically irrelevant. osesina et al. [21] build on the work of mutton using response-time analysis, which assumes that both temporal proximity and the cyclical nature of conversations can be used to perform edge prediction. the authors also use the content of the communications to build a word network, and then assign edges between users based on the keywords they use and the presence of these keywords in word clusters. finally, by combining these two approaches with direct addressing, they achieve impressive performance in edge prediction with regard to a manually extracted network, both in terms of edge existence and edge strength. it is worth noticing the significant computational requirement for large chat logs. besides the targeted task itself, the main difference with our approach is that this one is strongly content-based. gruzd and haythornthwaite [22] push the usage of direct referencing further by developing methods of name discov- ery. the data they work on come from a bulletin board which shares some similarities with regular chat: linear stream of messages with possibly intertwined discussion threads. by comparing a network extracted through their name discov- ery method, to a chain network based on temporal proximity, they show that their approach is better suited to detect social network links. useful takeaways of their method are: the use of neighboring words (for instance, dr., pr., and jr, are often seen in proximity of person names, whereas street and ave are often near location names), capitalization, and the position of words within the document (e.g., their sample of posts often end with a user's signature because a bulletin board does not have the ephemeral nature of chatrooms). however, these differences between the two media also makes this method unsuitable to our data. amtepe et al. [23] experiment on the detection of groups of users in chat logs, collected from three different chatrooms in the undernet irc network. they first build a matrix containing the numbers of messages posted by each user at each consid- ered time step. it can be considered as a low-resolution view of the logs--it retains information about temporal proximity but looses sequential information. they then perform singular value decomposition on this matrix, in order to ease the iden- tification of clusters of interacting users (i.e., conversations). they extract an approximation of the conversational network from this partition, by representing each cluster by a clique. they validate their approach by manually extracting the actual conversational network directly from the logs, and comparing their structures. the main difference with our situation is that 4ieee transactions on computational social systems, vol. 6, no. 1, february 2019 the conversational graph is only seen as a way to validate the user group detection method: we want to use it as a model of the interactions. forestier et al. [24] tackle the extraction of networks from online forums. while the structure of conversations is explic- itly represented on certain platforms, this it not the case there: a thread is represented as a flat sequence of messages. this makes it challenging to determine the intended recipient of a message. the authors show that by using a combination of grammatical analysis and levenshtein distance computation for substrings, they can often ascertain who talks to whom. the resulting network can then be used to analyse the role of users in the community. the main difference with our method is that we ignore the content of messages. travassoli et al. [25] explore different methods to extract representative networks from group psychotherapy chat logs. one of them includes fuzzy referencing to mitigate effects of misspelled nicknames, and rules for representing one-to- all messages. the bulk of the methods uses static patterns of exchanges to predict a receiver. their system shows a good agreement score with a human annotator. it is worth noting, though, that these logs are substantially different from ours: the psychotherapy sessions have well defined boundaries and a limited number of participants. this prevent the transposition of this approach to our problem. sinha and rajasingh [26] use only direct referencing, but with the same fuzzy matching strategy as in [25], in order to extract a network representing the activity in the #ubuntu irc support channel. this method manages to expose high level components of the ubuntu social network, which in turn allows for the qualification of user behaviors into specific classes such as beginner or expert. this method of building user models can be very interesting when the data describing the users are scarce, as is the case on irc where everyone can join and there is no requirement to register. while it does not allow for the direct classification of individual messages, the behavior information can be useful as a supporting feature in a text classification task. anwar and abulaish [27] build a framework allowing to query user groups and communities of interest, based on the data extracted from the computers of suspects during a criminal investigation. they use a social graph extraction method that relies both on the presence of communication between users and the overlap between the content of the messages they exchange, in order to assign weights to the edges of the network. they then experiment with various forms of community detection (i.e., graph partitioning) to identify groups of users in this network. however, this method assumes that the corpus contains a variety of topics allowing to discriminate the groups, which is not necessarily the case for us, since our logs are thematically dominated by the video game hosting the chatroom. an interesting task where conversational networks can be used is the detection of controversial discussions. garimella et al. [28] show that the predefined types of interactions allowed by twitter can be used to build networks that highlight the presence of polarized groups of users. they extract all tweets matching a given hashtag around the time a specific event happens, then detect an endorsement link thanks to twitter's retweet feature. the resulting graph is then partitioned and analyzed using a controversy measure. in our context it is difficult to adopt this approach, as endorsement information is not immediately available and would have to be inferred from message content. the methods proposed in the literature mainly rely on the content of the exchanged messages. by comparison, our method only focuses on the presence/absence of commu- nication between the users, i.e., on the dynamics of the conversation and its structure. some methods also rely on specific functionalities of the studied platforms (e.g., answers explicitly addressed to a user), which are absent from our own data. iii. methods in this section, we describe the methods that we propose to compute the features later used in the classification task to separate abusive and nonabusive messages. we first present how we extract conversational networks from series of raw chat messages (section iii-a), before describing the topo- logical measures that we use to characterize these networks (section iii-b). a. network extraction we extract networks representing conversations between users through a textual discussion channel. they take the form of weighted graphs, in which the vertices and edges represent the users and the communication between them, respectively. an edge weight corresponds to a score estimating the intensity of the communication between both connected users. we propose two variants of our method, allowing to extract undirected versus directed networks. in the latter case, the edge direction represents the information flow between the considered users. note that each network is defined relatively to a targeted message, since the goal of this operation is to provide features used to classify the said message. the method that we use to extract the networks repre- senting the conversations in which each message occurs has three steps that we describe in detail in this section. first, we identify the subset of messages that we will use to extract the network (section iii-a1). second, we select as nodes a subset of users which are likely receivers of each individual message (section iii-a2). third, we add edges and revise their weights depending on the potential receivers (section iii-a3). we describe and discuss the resulting conversational graphs in section iii-a4 1) context period: our first step is to determine which messages to use in order to extract the network. for this purpose, we define the context period, as a sequence of mes- sages. fig. 1 shows an example of context period, representing each message as a vertical rectangle. note that time flows from left to right in fig. 1. this sequence is centered on the targeted message (in red), and spans symmetrically before (left side) and after (right side) its occurrence. put differently: we consider the same number of past and future messages. the networks extracted from the context period contain only papegnies et al.: conversational networks for automatic online moderation 43 fig. 1. sequence of messages (represented by vertical rectangles) illustrating the various concepts used in our conversational network extraction process. figure available at 10.6084/m9.figshare.7442273 under cc-by license. the vertices representing the users which posted at least once on this channel, during this period. besides the network extracted over the whole context period (before and after the targeted message), which we call the full network, we also consider two additional networks. we split the period in the middle, right on the targeted message, and extract one network over the messages published in the first half (past messages), called before network, and one over the other half (future messages), called after network. both of those smaller networks also contain the targeted message. for a prediction task, i.e., when using only past information to classify the targeted message, one would only be able to use the before network. however, in a more general setting, all three networks (before, after, and full) can be used. 2) sliding window: in order to extract a network, we apply an iterative process, consisting in sliding a window over the whole context period, one message at a time, and updating the edges and their weights according to the process described next. the size of this sliding window is expressed in terms of number of messages, and it is fixed. it can be viewed as a focus on a part of the conversation taking place at some given time. it is shown as a thick black frame in fig. 1. we call current message the last message of the window taken at a given time (represented in blue), and current author the author of the current message. the use of such a fixed-length sliding window is a method- ological choice justified by four properties of the user interface of the considered discussion channel: 1) at any given time, the user can see only up to 10 preceding messages without scrolling; 2) when a user joins a channel, the server sends him only the last 20 messages posted on the channel; 3) it is impossible for a user to scroll back the history further than 20 lines; and 4) the user interface masks join and part events by default, whereas in typical chat clients the arrival and departure of users are shown by default. thus, at some given time, a user only has access to a limited knowledge regarding who is participating in the conversation. as explained later, we use this value of 20 messages as an upper bound, and experiment with different sliding window sizes. 3) weight assignment: our assumption is that the current message is destined to the authors of the other messages present in the considered sliding window. based on this hypothesis, we update the edges and weights in the following way. we start by listing the authors of the messages currently present in the sliding window, and ordering them by their last fig. example of sliding window (left) and computation of the corre- sponding receivers' scores (right). each color represents a specific user. each message in the window is filled with the color of its author (left), whereas the small squares represent direct references to users. a, b, and c columns represent different steps of the computation (right) (see text). figure available at 10.6084/m9.figshare.7442273 under cc-by license. posted message. only the edges toward the users in that list will receive weight. this choice is also due to the user interface constraints: a priori, a user cannot reliably know which users will receive a given message. furthermore, the data we have do not allow us to directly determine channel occupancy at the time a message is posted. fig. (left) displays an example of sliding window, in which the colors of the messages (vertical rectangles) represent their authors. so, in this specific case, four different users participate in the conversation. ordered from latest to earliest, these are: blue (author of the current message, i.e., the rightmost in the window), green, orange, and red. this list of users is noted a in fig. (right). obviously, a user is not writing to himself, so we remove the current author from the list, resulting in list b. the use of such an ordered list is justified by the assumption of temporal proximity, which appears commonly in the literature concerned with the extraction of conversational networks ( [20], [21], [23]). it states that the most recent a message, the most likely its author to be the recipient of the current message. the user interface allows us to explicitly mention users in a message by their name, and moreover the game prevents the users from changing their name: we need to take these properties into account. it is also a common assumption that the presence of direct referencing increases the likelihood that the referred person is the intended recipient of the message. to reflect this in our process, we move the users directly referenced in the current message at the top of the list. if some users are directly referenced although they have not posted any message in the considered window, they are simply inserted at the top of the list. in fig. 2, direct references are represented as small colored squares located in the current message. there are two of them in our example, referring to the purple and cyan users. the former has one post in the window, so he is moved from the third to the first rank in the list. the latter did not post anything in the window, so he is inserted at the first position. this results in what we call the list of receivers, which appears as list c in fig. 2. we now want to connect the current author to the receivers constituting our ordered list. our choice to create or update edges toward all users in the window even in case of direct referencing is based on several considerations. first, directly referencing a user does not imply that he is part of the conversation or that the message is directed toward him: for instance, his name could just be mentioned as an object of the sentence. second, there can be multiple direct references in 44 ieee transactions on computational social systems, vol. 6, no. 1, february 2019 a single message (as in our example). third, in online public discourse, directly addressing someone does not mean he is the sole intended recipient of the message. for instance when discussing politics, a question directed toward someone can have as a secondary objective to have the target expose his stance on an issue to the other participants. we also want to adjust the strength of each of these con- nections depending on the rank of the concerned receivers: the higher the rank, the stronger the interaction. for this purpose, each receiver is assigned a score, which is a decreasing function of both his rank i in the list and of the length n of this list (as reflected by the number of + signs in fig. 2). we propose three different scoring functions, defined so that the assigned weights sum to unity. 1) uniform: each receiver gets the same weight, defined as fu (i) = 1 n . (1) 2) linear: the score decreases as a linear function of the rank fl (i) = n - i n j=1 j . (2) 3) recursive: the first receiver gets 60% of the total weight, and the rest of them share the remaining 40% using the same recursive 60%--40% split scheme fr(i) =  0.6  0.4i-1, if 1  i < n 0.4i-1, if i = n. (3) as an illustration, fig. 3 displays the scores assigned by these three strategies for n = 10, as functions of the receiver's rank. the uniform strategy fu (in red line) assumes that the content of the communication is not really important, and that the goal of the current author is just to have the message seen by as much people as possible. it, therefore, places very little importance on temporal proximity or direct referencing. the recursive approach fr (in blue) gives the most importance to direct referencing and temporal proximity, with scores dropping fast when the receiver is not directly referenced or the author of the immediately preceding message. finally, the linear approach fl (in green) also places the most importance on temporal proximity and direct referencing, but in a less contrasted way, since it assigns higher scores (compared to fr) to receivers located at the bottom of the list. we later compare these three strategies during our experiments, in order to determine whether it is worth exploring more advanced scoring functions, or if the difference in performance is not significant enough to justify this. we can then update the graph by creating an edge between the current author and each user in the receiver list. we con- sider two possible approaches, leading to an undirected versus a directed network. in the latter case, the edge is directed from the current author toward the receiver, in order to model the communication flow. each newly created edge is assigned a weight corresponding to the receiver's score. if this edge already exists, we increase its current weight by the said score. fig. 4 shows the result of this update based on our previous example from fig. 2, for the extraction of an undirected fig. 3. scores assigned by our three scoring functions fu , fl , and fr for a receiver list containing 10 users. fig. 4. update of the edges and weights of the conversational graph corresponding to our ongoing example. the first graph displays the state before the update, and each remaining one corresponds to one rank in the receiver list. figure available at 10.6084/m9.figshare.7442273 under cc-by license. network. the first graph represents the network before the update. it already contains some edges though, resulting from some previous processing. the remaining graphs of fig. 3 rep- resent the changes corresponding to the ranks appearing in the receiver list: first position (purple and cyan users), second position (green line), and third position (orange line). red edges represent the edges being modified or created. if we were extracting a directed graph, then the new edges would be directed outward from the central blue vertex. once the iterative process has been applied for the whole context period, we get what we call the full network. as men- tioned before, for testing matters we also process two lesser networks based on the same context: the before and after networks are extracted using only the messages preceding and following the targeted message, respectively, as well as the targeted message itself. 4) extracted networks: fig. 5 shows a real-world example of the three conversational networks obtained by applying our extraction method to an abusive comment belonging to our dataset. they are obtained based on a context period of 200 messages, a sliding window of 10 messages, and are undirected. the isolates (disconnected vertices) present in the before and after networks correspond to users present in the context period, but active only after or before the targeted message, respectively. the red vertex corresponds to the author of the targeted message, which we call the targeted user. one can see that the users involved in the conversation, as well as the location of the targeted user in this conversation, undergo some dramatic changes after the abuse. generally speaking, two vertices are connected in our net- works if they are supposed to have a direct interaction. thus, if only one conversation occurs during the considered context papegnies et al.: conversational networks for automatic online moderation 45 fig. 5. example of the three types of conversational networks extracted for a given context period: before (left), after (center), and full (right). the author of the targeted message is represented in red dot. for readabil- ity reasons, weights and directions have been omitted. figure available at 10.6084/m9.figshare.7442273 under cc-by license. period, we expect the network to be rather cliquish. it seems possible to have several communities, i.e., several loosely connected dense subgraphs, if certain users completely ignore some other ones, for some reason. however, the smoothing induced by our use of a sliding window is likely to hide this type of behavior, especially if the window is large. the presence of a community structure could also occur if several distinct conversations take place during the considered context period. however, this can happen only if the number of common users between the conversations is small compared to the network size (otherwise, the communities will be indistin- guishable). due to the relatively dense nature of the networks (when ignoring isolates), we think weights are likely to be an important information, allowing to separate accidental edges from relevant ones. the edge direction allows distinguishing unilateral and bilateral interactions, so it could help identify certain types of conversations with atypical structure (e.g., one- way communication). b. features the classification features that we consider in this paper are all based on topological measures allowing to characterize graphs in various ways. we process all the features for each of the 3 types of networks (before, after, and full) described in section iii-a. we adopt an exploratory approach and consider a large range of topological measures, focusing on the most widespread in the literature. some of these measures can optionally handle edge directions or edge weights: we consider all practically available variants, in order to assess how informative these aspects of the graph are relatively to our classification problem. one can distinguish topological measures in terms of scale and scope. the scale depends on the nature of the character- ized entity: vertex, subgraph, or graph. in our case, we focus only on vertex- and graph-focused measures: the former allows focusing on the author of the targeted message, whereas the latter describes the whole conversation, but we do not have any subgraph to characterize. the scope corresponds to the nature of the information used to characterize the entity: microscopic (interconnection between a vertex and its direct neighborhood), mesoscopic (structure of a subgraph and its direct neighborhood), and macroscopic (structure of the whole graph). in the rest of this section, we describe these measures briefly: first the vertex-focused ones (section iii-b1), then the graph-focused ones (section iii-b2). for each measure, we give a generic, graph-theoretical definition, before explain- ing how it can be interpreted in the context of our conversa- tional networks. 1) vertex-focused topological measures: these measures allows characterizing only a single vertex. we compute them all for the vertex corresponding to the author of the targeted message (represented in red in fig. 5). a) microscopic measures: we start with the measures which describe a vertex depending on its direct neighborhood. in our context, this amounts to characterizing the position of some user depending on its direct interlocutors. in the case of a conversation involving a very small number of persons, it is likely all of them interact directly, and so these measures can also help describing the conversation itself. the degree centrality is a normalized version of the standard degree [46], [50], which corresponds itself to the number of direct neighbors of the considered vertex. in a directed graph, one can distinguish an incoming and an outgoing degree centrality, focusing only on the incoming and outgoing edges of the vertex, respectively. in our case, it can be interpreted as the number of users that have exchanged (undirected version), received (outgoing), or sent (incoming) messages to the author, respectively. we use both undirected and directed variants of the degree centrality. the generalization of the degree to weighted networks is called the strength [47]. the strength centrality is based on the sum of the weights of the edges attached to the considered vertex. like the degree, it is possible to use incoming and out- going versions if the network is directed. in our conversational graph, compared to the degree, the strength takes into account the frequency of the interactions. this allows accounting for certain situations ignored by the degree centrality. for instance, a user can have a few interlocutors, but still be central if he exchanges a lot with them. we use both undirected and directed variants of the strength centrality. the local transitivity (or clustering coefficient) [48] corre- sponds to the proportion of edges between the considered ver- tex's neighbors, relatively to what this number could be if all of them were interconnected. it ranges from 0 (no interneighbor edge at all) to 1 (the vertex and its neighborhood form a clique). in our context, a high transitivity indicates that the user belongs to a single conversation, in which most protagonists exchange messages. on the contrary, a low transitivity denotes some form of segmentation: either the user participates in several distinct conversations, or some of his interlocutors ignore each other. we use the unweighted original version and the weighted variant presented in [47]. burt's constraint [49] measures how redundant the neighbors of the vertex of interest are. it is based on the idea that a vertex located at the interface between several inde- pendent groups holds a position of power. burt's constraints measure this level of independence through a nonlinear com- bination of the number of connections between the neighbors. a high value indicates how embedded the vertex is in its 46 ieee transactions on computational social systems, vol. 6, no. 1, february 2019 neighborhood. in our case, this can help distinguishing users depending on the number of conversations they are involved in, if we suppose a conversation corresponds to a clique-like structure. we use both unweighted and weighted variants of burt's constraint. b) macroscopic measures: the measures harnessing the entirety of the graph structure form the largest group. in our context, they allow characterizing the position of a vertex relatively to the whole context period (full) or to one of its halves (before and after). so-called spectral measures are based on the spectrum of the graph adjacency matrix, or of a related matrix. the eigenvector centrality [34] can be considered as a generalization of the degree, in which instead of just counting the neighbors, one also takes into account their own centrality: a central neighbor increases the centrality of the vertex of interest more than a peripheral one. central vertices tend to be embedded in dense subgraphs. we use the (un)weighted and (un)directed variants of the measure (so: four variants in total). one limitation of the eigenvector centrality is that if the graph is directed and not strongly connected, certain vertices systematically get a zero centrality, whatever their position. several modifications have been proposed to handle this situation. the hub and authority scores [35] are two com- plementary measures processed through the hyperlink-induced topic search algorithm. they solve the issue by splitting the centrality value into two parts: one for the incoming influence (authority), and the other for the outgoing one (hub). we use the (un)weighted directed variants of both hub and authority scores. the alpha centrality (or katz centrality) [36], [51] solves the same problem by assigning a minimal positive centrality value to all vertices. in addition, it allows attenuating the influence of distant vertices during the computation. we use the (un)weighted directed variants of this measure. the power centrality [37] generalizes both the eigenvector and alpha centralities. in particular, it allows a negative attenuation. the implementation we use only works for unweighted directed (ud) graphs. the pagerank centrality [38] can be seen as a variant of the katz centrality. one limitation of the later is that when a central vertex has many outgoing edges, all of them receive all its influence, as if they were its only recipient. the pagerank centrality includes a normalization allowing to model the dilution of this influence. we use the (un)weighted and (un)directed variants of this measure. compared to the other spectral measures, the subgraph cen- trality [39] defines the notion of reachability based on closed walks rather than simple walks. put differently, the other spectral measures consider that the vertex of interest influences (resp. is influenced by) some other vertex if a walk exists to go to (resp. come from) this vertex. the subgraph centrality requires both, and it uses an attenuation coefficient to give less importance to longer walks. the implementation we use only deals with undirected unweighted graphs. in our conversational graph, we expect that a user participat- ing a lot in the conversation will be central, and even more so if there are several conversations and he is participating in the main one. it is difficult to predict which ones of these slightly different spectral measures will be the most appropriate to our case, which is why we included all of the available ones. another group of macroscopic measures is based on the notions of shortest path or geodesic distance (i.e., the length of the shortest path). the betweenness centrality [40] is related to the number of shortest paths going through the considered vertex. in com- munication networks such as ours, it can be interpreted as the level of control that the user of interest has over information transmission. we use the (un)weighted and/or (un)directed variants of this measure. the closeness centrality [41] is related to the reciprocal of the total geodesic distance between the vertex of interest and the other vertices. it is generally considered that it measures the efficiency of the vertex to spread a message over the graph, and its independence from the other vertices in terms of com- munication. the eccentricity [42] is related to the closeness centrality, but it is not a centrality measure. on the contrary, it quantifies how peripheral the vertex of interest is, by con- sidering the distance to its farthest vertex. by comparison to the closeness centrality, there is no reciprocal involved, and it uses the maximum operator instead of the sum. in our case, both measures indicate how involved the considered user is in the conversation(s), as they directly depend on how directly connected he is to the other users. in particular, we expect important changes in the before and after graphs to reflect a significant modification of the user's role in the conversation. for the closeness centrality, we use the (un)weighted and (un)directed variants, but for the eccentricity, we only have access to the unweighted (un)directed variants. the last group of macroscopic measures is based on the notion of connectivity, i.e., whether or not a path exists between certain parts of the graph. an articulation point (or cut vertex) is a vertex whose removal makes the graph disconnected, i.e., split it into several separate components [42]. we define a binary nodal feature indicating if the vertex of interest is an articulation point (1) or not (0). it could help describing whether the targeted user is bridging two separate groups of users in the conversation, possibly indicating that he caused a topic shift or that some of the users have left the conversation. c) mesoscopic measures: mesoscopic measures rely on an intermediate structure to characterize a vertex. in our case, such a subgraph corresponds to a tightly knit group of users, and is likely to represent a conversation. so, this type of measure would allow characterizing the position of a vertex relatively to the various conversations taking place in the considered context period (provided there are several of them). the coreness score [43] is based on the notion of k-core, which is a maximal induced subgraph whose all vertices have a degree of at least k. the coreness score of a vertex is the k value of the k-core of maximal degree to which it belongs. in our context, the coreness score is related to the number of participants of the largest conversation involving the user of interest. we use an undirected version of the coreness score, as well as two variants focusing on incoming and outgoing edges in directed networks. papegnies et al.: conversational networks for automatic online moderation 47 we also take advantage of the within-module degree and participation coefficient, a pair of complementary measures defined relatively to the community structure of the graph [44]. we detect the community structure through the infomap method [52]. these measures aim at characterizing the position of a vertex at this intermediate level. the within-module degree (or internal intensity) assesses the internal connectivity. it evaluates how the degree of a vertex within his community relates to those of the other vertices from the same community. for us, it is an indicator of how involved the user is in his current conversation. the participation coefficient is concerned with the external connectivity: it is based on the number and quality of the connections that the vertex has outside of his own community. in our case, a high value could indicate either someone holding a mediation position, in the case of a single conversation involving several groups of users, or someone participating in several conversations. we use the original undirected variants of these measures, as well as the directed variants proposed in [53] to focus on incoming and outgoing edges. one limitation of the participation coefficient is that it mixes several aspects of the external connectivity: the number of external connections, the number of concerned external communities, and the distribution of these connections over these communities. to solve this issue, three measures were proposed in [45] to separately assess these three properties. they are, respectively, called external intensity, diversity, and heterogeneity. the available variants are all unweighted, but allow handling undirected, incoming, and outgoing edges. 2) graph-focused topological measures: a simple way to obtain graph-focused measures is to consider a vertex-focused measure and compute some statistic over the vertex set of the graph. this is what we do for all of the 21 measures described in section iii-b, by averaging them over the whole graph. this also holds for all the variants (weighted and/or directed) of these measures. but there are also measures defined specif- ically for the graph scale: like before, we distinguish them based on their scope. a) microscopic measures: first, we use very classic statistics describing the graph size: the vertex and edge counts. we also compute the density, which corresponds to the ratio of the number of existing edges to the number of edges in a complete graph containing the same number of vertices. in other words, the density corresponds to the proportion of existing edges, compared to the maximal possible number for the considered graph. in our context, these measures allow assessing the number of users considered in a context period (vertex count), and the general intensity of their communication during this period (edge count). the density can be viewed as a normalized edge count that is more likely to be useful when comparing graphs of different sizes. the global transitivity (or global clustering coefficient [31] is the graph-focused counterpart of the local transitivity. it corresponds to the proportion of closed triads among connected ones, where a closed triad is a three-clique (i.e., a triangle) and a connected triad is a subgraph of three vertices containing at least two edges. this proportion measures the prevalence of triadic closure in the graph. in our context, it assesses how likely two users communicating with the same person are to directly exchange messages themselves. we only have access to the undirected unweighted version of this measure. the reciprocity [32] is defined only for directed graphs. it corresponds to the proportion of bilateral edges over all pairs of vertices. in our networks, a low reciprocity would indicate that certain users do not respond to others. the degree assortativity (or assortativity for short) [33] measures the homophily of the graph relatively to the vertex degree. the homophily is the tendency for vertices to be connected to other similar vertices (in this case: of similar degree). it is based on the correlation between the series con- stituted of all pairs of connected vertices. we use both directed and undirected variants of this measure. in our conversational networks, this measure could help detect situations where users do not participate to the conversation at the same level. b) macroscopic measures: a number of macroscopic measures are connectivity-based. the weak component count corresponds to the number of maximally connected subgraphs. in such a subgraph, there is a path to connect any pair of vertices. for our conversational networks, this could corre- spond to a conversation, whose participant do not necessarily talk directly to each other. however, due to the use of a sliding window, we expect our graphs to be connected (i.e., only one weak component), even if by very weak edges. in this case, a conversation is more likely to correspond to other substructures based on more relaxed definitions, such as cliques or communities. for directed graphs, we also consider the strong component count: a strong component is similar to a weak one, except it is based on directed paths. we suppose that, in our networks, we are more likely to get several strong components, since users do not necessarily exchange in a bilateral way. the cohesion (or vertex connectivity) of a graph corre- sponds to the minimal number of vertices one needs to remove in order to make the graph disconnected (i.e., have several components) [29]. the adhesion (or edge connectivity) is similar, but for edges. in our conversational networks, these measures can be related to the level of participation to the considered conversation: the higher their values, and the higher this level. but high values can also denote the presence of several distinct conversations in the context period. both measures are defined for directed networks. as mentioned before when describing the nodal measures, we check whether the targeted user is an articulation point. we also compute the articulation point count, i.e., the total number of articulation points in the graph. this measure is related to the cohesion, since there are no articulation point if the cohesion is larger than 1. the implementation we use handles only undirected graphs. in our context, the number of articulation points could be related to the presence of several conversations (articulation points corresponding to gateway users between them). it could also reflect situations where a conversation lasts a very long time, and some groups of users loose interest and get disconnected from the active users. another possibility is the occurrence of a flood-type situation: a user sends a flurry of messages into the channel to kill a 48 ieee transactions on computational social systems, vol. 6, no. 1, february 2019 conversation, then leave, and a different group of users later takes possession of the channel to start its own conversation. we also use three distance-related measures. the first is the diameter, which corresponds to the largest distance found in the graph, i.e., the length of the longest shortest path. it also corresponds to the largest eccentricity over all vertices. we use (un)weighted and (un)directed variants. the second is the radius, which is the smallest eccentricity over all vertices. we use its undirected, incoming and outgoing variants. the third is the average distance, which is the average length of the shortest paths processed over all pairs of vertices. we use its unweighted (un)directed variants. in our networks, the distance is related to the separation between users, in terms of interaction. a large diameter means that a user can be many intermediaries away from exchanging directly with another user. this could be caused, for instance, by the occurrence of several distinct conversations in the considered context period, or by a very long conversation loosing and gaining users through time. this observation also holds for the radius and average distance, which provide a slightly different per- spectives on the same aspect of the graph. c) mesoscopic measures: we process the total clique count in the network, where a clique is a complete induced subgraph. as mentioned eralier, this can be related to the number of conversations occurring in the context period, or to number of subgroups of users participating in the same con- versation. like before with vertex-focused measures, we use the infomap algorithm to detect the community structure [52]. based on this partition, we compute two measures: the com- munity count and the modularity [30]. the latter assesses the quality of the detected community structure, i.e., how inter- nally cohesive and externally disconnected the communities are. we use both weighted and unweighted variants of the modularity. iv. experiments this section describes our experimental setup and results regarding the automatic detection of abusive messages in chat logs. in section iv-a, we present our dataset and the general architecture of our classification system. because we expect some of our features to be redundant, we conduct a correlation study of our feature set in section iv-b. we present general results and the effect of our various graph extraction parameters in section iv-c. in section iv-d, we investigate the temporal aspects of the system --specifically what happens when we train our models based on the features extracted from only one of the three graphs (before, after, or full), or some of their combinations. we then examine the importance of weight and directionality in section iv-e, before investigating the potential for computational optimization through feature selection in section iv-f. finally, in section iv-g, we compare the performance obtained using the best configuration of our framework with the selected baselines. a. experimental setup we have access to a database of 4 029 343 messages that were exchanged by the users of the browser-based multiplayer game spaceorigin, a french-language massively multiplayer online game. in this database, 779 messages have been flagged by one or more users as being abusive, and subsequently confirmed as abusive by the human game moderators: they constitute our abuse class. each message belongs to a unique communication channel. a total of 226 distinct users have authored these abusive messages. we further extract 2000 mes- sages at random from the messages not confirmed as abusive, to constitute the nonabuse class. note that all the results we discuss in this paper are relative to the abuse class. we previously experimented with this dataset in [3] and [17]. however, since then we have detected certain inconsistencies in the database, preventing us from retrieving the context of certain messages. we cannot apply our classification method to them, so we discard them for the work presented here. note that this concerns both classes. moreover, our tests show that removing those samples does not significantly impact our previous performances. the resulting dataset is constituted of 1890 messages in the nonabuse class and 655 messages in the abuse class. fig. 6a shows the distribution of abuse cases by user. it suggests that most abusive users need only a few warnings before mending their ways, but it also shows that some users are exceptional in the number of abuses they commit. because of the relatively small dataset, we set up our experiment for a tenfold cross-validation. we split the dataset into 10 same-sized parts containing the same ratio of abusive to nonabusive messages. we use a 70%-train / 30%-test split, which means, for each run of the cross-validation, the train set is composed of 7 of those parts while the test set is composed of the remaining 3. we use python-igraph [54] to extract the conversational networks and process the graph-based features for each message. as a classifier, we use a support vector machine (svm), implemented in the sklearn toolkit [55] under the name c-support vector classification. we mainly experiment with 4 different sets of features: full, before, after, and all. for a given message, before, after, and full correspond to all the topological measures computed for the before, after, and full graphs, respectively. all is the union of all three sets, i.e., it includes all topological measures for all three graphs. in the remainder of this section, we occasionally provide computational time requirements. for context, the times that we provide correspond to single-threaded calculations performed on an intel xeon cpu e5-2620 v3s, clock speed 2.5-ghz and 15-mb cache. b. feature dependence study each considered topological measure was originally defined to characterize a graph in a specific, distinct way. so, in theory, they could all be independent for a given graph, and thus all necessary to describe it completely. but in practice, according to the structure of the considered graph, some of them can be statistically dependent, and, therefore, redundant. in order to get a better understanding of the way these topological measures behave on our conversational graphs, we compare all the computed features using pearson's correlation coefficient. papegnies et al.: conversational networks for automatic online moderation 49 fig. 6. a) distribution of the number of abuse cases by user. b) classification performance (f-measure) as a function of the context period size, for a sliding window of 10 messages and using the recursive weight assignment strategy ( fr). c) classification performance (f-measure, in blue) and number of abuse occurrences in the context period (red), as functions of the context period size. in our context, where these features are later fetched to a classifier, only the strength of the association is relevant, i.e., the absolute value of the correlation (not its sign). we identify clusters of highly correlated features using the hclust function of the r language, which implements a standard hierarchical cluster analysis method, with average linkage. we use the silhouette measure [56] as a criterion to select the best cut in the produced dendrograms. to keep the description short, we only focus on the most interesting results. a very small number of features are constant over all instances of the corpus, which means they have no discrimina- tive power at all. for all three types of networks, the number of weak components is always 1, which means they are always (weakly) connected. this can be explained by our use of a sliding window: even if the context period contains two separate conversations, they will be connected, possibly by an edge of quasi-zero weight. in the after and full graphs, the targeted user is never an articulation point. moreover, in the full graph, the number of articulation points is always zero. we already know that the graphs are connected, so this zero value means no single vertex removal can disconnect them. a few features are quasi-independent, in the sense they display almost no correlation with any other feature. this is the case of certain variants of the power, subgraph, and alpha centralities. from this point of view, they differ from the other spectral measures, which are overall strongly correlated. certain variants of measures focusing on connectivity (strong component count, adhesion, cohesion, and radius) are also independent, and it is the case for a number of mesoscale features too, all of them based on the community structure. the fact that these features are only weakly (if at all) correlated to the others makes them singular, in the sense they are the only ones to capture certain structural changes in the conver- sational graphs. but it does not imply they have any particular discriminative power regarding the classification task at hand. however, they must be closely monitored in the rest of our experiments, because they constitute good candidates. the rest of the features forms highly correlated clusters, some of which are homogeneous in terms of measure variants, while some are heterogeneous. as explained in section iii-b, for each topological measure we consider several variants to define our features: directed vs. undirected, weighted vs. unweighted, averaged vs. individual. in our case, certain variants of the same measure are strongly correlated, which makes them redundant for our purpose. in particular, a very large number of measures, mainly distance- and community- based, have strongly correlated direction-based variants. this indicates that most of the time, considering the direction of the interactions between users does not bring any addi- tional information. this effect is clearly much less marked for average-based and weight-based variants. thus, unlike direction, weight seems like an important aspect of our graphs, and averaging measures over all vertices also seems to bring some relevant information. overall, we observe different behaviors, which cannot be explained only by the various characteristics of the features (micro/meso/macroscopic, un/directed, un/weighted, before/after/full graphs). this supports our decision to adopt an exploratory approach to identify the most appropriate features for our classification problem. the detected clusters of correlated features will be useful later to ease the interpretation of the classification results, as features belonging to the same cluster can be considered as interchangeable. c. impact of graph extraction parameters as explained in section iii-a, our graph extraction method has three important parameters: 1) size of the context period; 2) size of the sliding window; and 3) weight assignment strategy. in this section, we explore how the classification performance varies depending on these parameters. our goal here is both to get a better understanding of the parameters role, and to identify the most appropriate values without having to use brute force. as a reminder, the context period is the sequence of mes- sages considered to classify the targeted message, and symmet- rically built around this message. we expect it to have a strong effect on the classification performance, depending on its size. if it is too small, one can suppose it only includes a part of the conversation containing the targeted message, and, therefore, lacks some information necessary to make a proper decision regarding the abusive nature of this message. on the contrary, if it is too large, we assume it contains several conversations having nothing to do with the targeted message, which should also result in lower classification performance. in summary, 50 ieee transactions on computational social systems, vol. 6, no. 1, february 2019 fig. 7. a) classification performance (f-measure) for the 3 considered weight assignment strategies (uniform, linear and recursive) and context period sizes (200 and 1,350 messages), as a function of the sliding window size. b) classification performance (f-measure) as a function of the context period size (in messages), for the 4 considered feature sets (before, after, full, all) as well as a combination of the first two of them (before + after). c) performance (f-measure) obtained for the (un)directed and (un)weighted feature sets, as a function of the context period size. when using a growing context period, we expect the classifica- tion performance to increase, then reach a plateau correspond- ing more or less to the typical duration of a conversation, and then decrease as the context period contains more and more noise (i.e., information not related to the targeted message). fig. 6b shows the evolution of the classification perfor- mance, expressed in terms of f-measure for the abuse class, as a function of the context period size, as for it expressed in numbers of messages. we fix the sliding window to 10 messages, and the recursive strategy fr to assign weights. all available features (all feature set) are used during the classification. we choose these extraction parameters because earlier testing showed that the recursive strategy yielded the best performance, and this sliding window size provides a good tradeoff between a graph that would be very sparse and, therefore, not informative enough, and one that would be very dense and thus too noisy. it appears that our assumption is only partially verified: the performance first increases with the context period size. however, it does not reach a plateau as expected, and, on the contrary, seems to go on increasing, albeit more and more slowly, as if it was logarithmically depending on the context period size. the maximal performance is obtained for a size of 1350 messages, but it is possible that even higher values can be obtained for larger context periods (which we did not check due to computational limitations). this means that our assumption regarding that large context periods would bring mainly additional noise is incorrect, because, on the contrary, they convey more relevant information concerning the classification task. we manually investigate a sample of our dataset to understand this trend. from reading a number of conversation logs, it first appears that conversation boundaries are not well defined, and so there is no typical duration for a conversation: this can explain the absence of a plateau in the plot. furthermore, we based our assumptions with regard to performance on the idea that an abusive message has a specific impact on what happens after it is posted. specifically, the conversation would show markers of normality before the message occurs and quickly devolves after that. as it turns out, in conversations where an abusive message is found, the author of the abusive message usually has been around for a while, and the message that is actually flagged and confirmed as abusive is not his first suspicious message. we assume that the classifier can take advantage of this type of situations, therefore, invalidating our previous assumption that a large context period would only bring noise. note that more than one message of the abuse class can co-occur, i.e., can appear in the same context period, if it is large enough, which also supports our point. this is generally due to a single user sending multiple abusive messages in quick succession, or because the conversation devolves into name-calling following an initial abusive message. fig. 6c shows the number of co-occurring abusive messages, as well as the f-measure performance, as functions of the size of the context period. there is a very strong match between both series, even if not perfect. this seems to back our assumption of the classifier taking advantage of the potential abuse cases happening around the targeted message. all these observations regarding the co-occurrence of abuse expose a couple of interesting perspectives: 1) user models can presumably yield features useful for classification and 2) a text-based model of the whole conversations would also likely be useful. we now explore the impact of the window size and weight assignment strategy on the overall performance. fig. 7a shows the evolution of our performances for two fixed sizes of context periods (200 and our previously obtained optimum of 1350). the maximal window size considered is 19, which corresponds to almost twice the default gui limitation (cf. section iii-a2). for our optimal context size, we obtain the best results for a window size of 9 and the linear assignment strategy, and for the window size 10 and the recursive assignment strategy. both of those strategies give greater importance to temporal proximity. overall, there is no much difference between our weight assignment strategies. it seems that the specific values of the weights are not as important as their relative ordering. it is also worth noting that those window sizes are very close to the natural limitation of the gui, which means they likely best capture the intended recipients of any given message. d. temporal aspects the results shown until now are all obtained using the all feature set, i.e., the features resulting from the calculation of papegnies et al.: conversational networks for automatic online moderation 51 all topological measure variants for all three individual graphs (full, before, and after). however, using the full or after graphs restricts the possible use cases for the system to tasks that do not require taking a decision as soon as the message to classify becomes available since the "future" context of the targeted message is taken into account. in order to have a system that is capable of doing so, we must investigate the impact of the before features. studying the features from the three individual graphs also allows us to get a better understanding of the system by providing a qualitative and accurate analysis of each part of the context. fig. 7b shows the results obtained for classifiers built using combinations of the available feature sets: after, before, and full correspond to each graph considered separately, whereas before + after denotes the union of the before and after sets, and all represents the set of all computed features (before, after, and full). the conversational graphs used for these experiments are extracted using the recursive assignment strategy fr and a sliding window of 10 messages. unless stated otherwise, we use these parameters in the rest of this paper as they match the best performance obtained during our greedy search of the parameter space (section iv-c). since the main idea behind our approach is to detect the nature of a message based on the reaction it triggers in the community, it is not surprising to see that the after feature set (in red curve) reaches an acceptable performance level on this task. however, what is surprising is that by using only the before feature set (in blue curve), the system performs much better on the same task (at least for small context periods). this suggests that the interactions occurring before the targeted message reveal more about its abusive nature than those happening after. nevertheless, when using large context periods, the perfor- mances obtained for before and after get very similar. this indicates that what is important is not whether the messages used to extract the conversational graph precede or follow the targeted message, but rather how many of these messages are used. this supports our previous finding, regarding the fact that the context period size is the most important parameter of our graph extraction procedure. moreover, based on the same observation, one could also think that the before and after graphs convey approximately the same information, when considering large context periods, because the corresponding performances are roughly the same. however, this is disproved by the results obtained for the union of the before and after feature sets (in yellow): the classification performance is noticeably higher, which means both types of graphs do not completely overlap, informationally speaking. it is worth noticing that we get almost the same performance with the full feature set as with before + after. one could assume that the use of two distinct graphs built on either sides of the targeted message would help better characterizing it, compared to the full feature set, which covers the same time span based on a single graph. indeed, when extracting the latter, the sliding window passes through the targeted message, and is likely to smooth the potentially relevant topological changes occurring right around it. however, even if the performance gap between before and after seems to widen when the context period gets larger, the difference is not clear, so this assumption is not verified. this means that the single full graph is as approximately as informative as the joint use of both before and after graphs. the latter option procures more flexibility in the possible application scenarios, but it contains twice as many features, and, therefore, requires roughly twice the computational time. this observation is confirmed when we consider the all feature set (in green), which contains all features for all three graphs. as expected, it performs best overall, since it is the union of all the other considered feature sets. however, the results are only marginally better than for full and before + after. this means that the information conveyed by the full and before + after feature sets essentially overlaps: using their union does not bring any noticeable performance increase. e. impact of weights and directions we now investigate how considering the edge weights and directions in our features affects the classification performance. based on the all feature set, we define four new feature sets, characterized by their focus on unweighted undirected (uu), ud, weighted undirected, and weighted directed measures, respectively. concretely, each set includes the same group of core features, which are conceptually not concerned by the notion of weight or direction. this core is completed by features designed to consider or ignore weights or directions. for instance, the clique count is a core feature, whereas each one of the four variants of the diameter appears in a specific set. fig. 7c displays how the corresponding classification per- formance (in terms of f-measure) evolves as a function of the context period size. it appears that both weighted feature sets (blue and yellow) dominate their unweighted counterparts (green and red curves) over the considered interval. this seems to confirm our assumption from section iii-a, regarding the fact that weights can help discriminate between certain structures of conversations, and/or distinguish consecutive conversations. there is a similar effect for directions, but it is much weaker, as each directed feature set (red and yellow) only partially dominates its undirected counterpart (green and blue). this is consistent with our observation from section iv-b, regarding the high correlation noticed for certain measures, between their undirected and directed variants. this indicates that the direction of edges is not as relevant as their weight relatively to the classification task at hands. yet, the best performance is reached when using both weights and directions. if the additional computational cost is not too high (and it is generally not the case), it is, therefore, worth using directed features. f. feature contributions in order to estimate the discriminative power of our features with regard to this classification task, we use a recursive feature elimination method. it takes a given feature set as input, and outputs its subset of so-called top features (tfs). these are the minimal subset of features allowing to reach 97% of the performance obtained when considering the input 5ieee transactions on computational social systems, vol. 6, no. 1, february 2019 table i comparison of the performances obtained with the feature sets (all, before, full, and after) and their subsets of top features (tf). the total runtime is expressed as day:h:min:s feature set. in order to identify these tfs, we apply an iterative method based on sklearn. this toolkit allows us to fit a linear kernel svm with the values of the input feature set, and provides a ranking of the individual features in that set, reflecting their relevance to the classification task. we then drop the least important feature, and train a new model using all the remaining features. we repeat this process until the classification performance reaches the targeted minimal threshold of 97% of the original f-measure score. we first apply this recursive feature elimination process to the all feature set in order to identify the overall best features, then do the same with the before, after, and full feature sets, for comparison purposes. table i presents the performances and computational time costs measured for each of these complete feature sets, as well as for their respective tf subsets. it appears that, for all four feature sets, using the tfs during the classification allows reducing the runtime by up to 4 orders of magnitude, while retaining at least 97% of the f-measure value, which is very interesting from an application perspective. it means that the longer features to process do not bring more discriminative power than the shorter ones, regarding the classification task at hand (at least for our dataset). the fourth column describes the average runtime by message, and shows that the classifier could operate in real-time when limited to the tfs. it is important to notice that feature computation is by far the most computationally expensive step of our framework. by comparison, extracting the conversational graphs for the full corpus takes around 3 min, and performing the whole cross-validation (i.e., tenfold training and testing) only 1 min. the time required to compute our features depends on the size of the conversational graph, in terms of number of vertices and/or edges. the graph size is affected, in turn, by the number of users involved in the conversation (number of vertices) and the density of exchanged messages (number and weights of the edges). these characteristic are bounded by social and ergonomic (e.g., user interface) constraints, and can therefore be assumed as independent from the corpus size. the scalability of our method thus depends on that of the tool selected to perform the classification step: it is an svm in this paper, but the end-user is free to use any other classifier instead. as explained in section iv-b, certain of our features are strongly correlated, which led us to identify clusters of table ii clusters containing the tfs (in bold) obtained for the all feature set. the letters in the graph column stand for before (b), after (a), and full (f). those in the scale column mean graph-scale (g) or vertex- scale (n). those in the wght. (weights) and dir. (directions) columns stand for: unweighted or undirected (u), weighted (w), directed (d), incoming (i) and outgoing (o). interchangeable features. studying the tfs would result in missing this information: we must consider their clus- ters instead. table ii displays the nine clusters corresponding to the tfs obtained for the all feature set. for matters of space, we discuss in detail this sole feature set only. note that these clusters generally contain several variants of one (or more) topological measure(s), as indicated by the four last columns. for instance, cluster 10 contains all variants of average weighted and uu eigenvector centrality for all three types of graphs (before, after, and full). also note that a letter g in the scale column can either refer to a naturally graph-scale feature, or to a vertex-scale feature averaged over v (cf. section iii-b). for completeness, the proper tfs are represented in bold. cluster 9 contains only micro- (degree, strength, burt's constraint) and meso-scopic (clique count, coreness) features describing the after and full graphs. moreover, all of them are graph-scale (as the vertex-scale measures are averaged over the graph). in contrast, cluster 41 focuses on the same graphs and also contains the degree and strength, but as vertex-scale features this time. put differently, cluster 41 can be viewed as a vertex-scale counterpart of cluster 9. this indicates that the microscopic characteristics of both the targeted vertex and the whole graph are relevant to our classification task. cluster 10 is very large and contains almost only graph- scale features. it focuses mainly on distance-based (diameter, papegnies et al.: conversational networks for automatic online moderation 53 average distance, radius, closeness, eccentricity) and spectral (hub/authority, eigenvector, pagerank) macroscopic measures. like the previous clusters, it essentially contains features computed on the after graph, but unlike them, it includes only a few features from the full graph. nevertheless, it appears as quite complementary of cluster 9, in the sense it can be considered as its macroscopic counterpart. cluster 49 suggests that the betweenness of the after and full graphs mechanically increases with their number of vertices. but more importantly, it identifies the vertex count, i.e., the size of the conversation after the targeted message, as one of its most discriminative aspects, relatively to our clas- sification task. the interpretation of clusters 17and 177 is even clearer, as each focus on a single measure (reciprocity and closeness), uniquely for the after graph. the bilateral nature of the exchanges after the targeted message, as well as how direct these are, can, therefore, also be considered as very important for the classification. clusters 110 and 118 deal only with the before graph. cluster 110 includes variants of the weighted closeness (both for the targeted vertex and in average) and density. it can be considered as the before counterpart of cluster 177, which also focuses on the weighted closeness but for the after graph. cluster 118 contains distance-based and spectral macroscopic measures, mainly describing the whole graph. thus, although much smaller, it can be seen as the before counterpart of cluster 10, semantically speaking. finally, cluster 119 contains the unweighted hub and authority scores of the targeted vertex, for both after and before graphs. it can be opposed to both clusters 10 and 118, which also contain hub and authority for the after and before graphs, respectively, but in their weighted and averaged versions. let us summarize our observations. a number of composite clusters describe the after/full (clusters 9, 10, and 41) and before (cluster 118) graphs at various scales and scopes. two clusters focus more precisely on the closeness, for the before (cluster 110) and after (cluster 177) graphs. we assume that the classifier is able to take advantage of this to compare various aspects of the graphs, be it in terms of scale (clusters 9 versus 41), scope (clusters 9 versus 10) or time (cluster 10 versus 118 and 177 versus 110). this means that 1) temporal aspects are useful for this classification task and 2) an abuse case is reflected by its impact on both the position of the abusive user in the graph and the overall aspect of the conversation. each remaining cluster (49, 119, and 172) focuses on a mea- sure of the after graph, highlighting their contribution to class discrimination. we examine more thoroughly these features, by considering separately their distributions in the abuse and nonabuse classes. for the number of users in the conversation, it turns out these distributions are quite different: the vertex count is relatively homogeneous and centered around 40 for the abuse class, whereas its distribution is heterogeneous (closer to a power law) when there is no abuse, with a very large number of very small networks (less than five users). looking at the reciprocity, there is again a relatively homo- geneous distribution for the abuse class, centered around 0.7. for the nonabuse class, a part of the distribution is quite similarly homogeneous (albeit around 0.6), but the large majority of instances have either a 0 or 1 reciprocity, i.e., only unilateral or bilateral edges, respectively. after verification, the former case corresponds to conversations that come to an abrupt end, whereas the latter is just a normally functioning conversation. both cases are more likely to happen when few users are involved, which is consistent with our observations regarding the vertex count. however, both features are only partially correlated, which shows that the abuse class cannot be reduced only to a question of number of users involved in the conversation. the closeness seems to have a special role, since its weighted variants constitute their own clusters for the before (cluster 110) and after (cluster 177) graphs. by comparison, the average unweighted closeness is correlated with many other features as it belongs to the large cluster 10: this is consistent with our previous observation that certain weighted variants appear to be more informative. further examination shows that the closeness follows a power law-like distribution in both classes, covering 3 orders of magnitude. however, this heterogeneity is much more marked in the case of the nonabuse class. concretely, the closeness is generally higher for the abuse class. this means that the average distance between the author of the targeted message and the rest of the graph decreases in case of abuse. this user becomes less peripheral (or more central), and the same goes for the other users of the graph (in average). this fits in quite well with assumptions about how abuse impacts a discussion: an abuser would tend not to be peripheral in a conversation, while we can reasonably assume that the other participants will be piling on and, therefore, be less peripheral themselves. most mesoscopic measures are discarded during the feature elimination process. the only remaining ones are the clique count and the coreness, which are also the only ones not related to community structure. yet, we had considered them as promising in section iv-b, because they are uncorrelated with the others: it turns out the unique information they convey does not help solving this specific classification task. inspec- tion reveals that the modularity measure is overwhelmingly close to zero in both classes. this means that our networks generally do not have any community structure, which explains why the related features are not discriminative here. we also have identified and studied the clusters correspond- ing to the tfs of the before, after, and full feature sets. for matters of space, we do not present them in detail, though, and only discuss our most interesting observations. certain clusters identified for the all feature set also appear for the other sets: those focusing on the considered type of graph, i.e., clusters 110 and 118 for before; 10, 41, 49, and 177 for after, and 9, 10, 41, and 49 for full. some of the missing clus- ters are replaced by semantically close and relatively correlated clusters. for instance, before has a cluster containing exactly the same measure variants as cluster 49 (vertex count and betweenness), but for the before graph. similarly, full has a cluster focusing on the weighted closeness, as cluster 177 does for after. we interpret clusters 9 and 41 as describing the microscopic aspects of the after graph at the graph and vertex 54 ieee transactions on computational social systems, vol. 6, no. 1, february 2019 table iii best performances for the baselines and current framework scale, respectively: before has comparable clusters focusing similarly on the before graph. overall, we can say that when focusing on a specific type of graph (by opposition to all), the classifier takes advantage of informationally close clusters, albeit inferior in terms of discriminative power, as they lead to a lower performance. g. baseline comparison for matters of exhaustiveness, we assess the performance of our framework on a balanced version of our classes, instead of the unbalanced ones used throughout this section. in this setting, the abuse class stays the same, but the nonabuse class is reduced to the size of the abuse one, through sampling. when using these data, we observe a significant performance improvement for all feature sets. in particular, the f-measure values obtained for all and all-tf increase from 83.99 and 82.65 to 88.87 and 87.10, respectively. further investigations shows that this improvement is mainly due to a decrease in the number of false positives, itself caused by the smaller size of the nonabuse class. such a balanced situation is unlikely in practice, though. finally, we compare the results obtained using our frame- work with our two baselines (table iii): the content-based approach of [17] and the previous version of our graph-based method [3]. as a reminder, the main differences between the latter and our present framework are that we now extract a directed graph, and use a much larger number of topolog- ical measures as classification features. the combination of these two improvements leads to a significant performance increase over our previous effort. as described in section iv-e, the contribution of edge directions to the overall performance is relatively minor. one could assume that the performance improvement is mainly caused by the major expansion of the feature set, however, this improvement is observed even when only using the tfs identified in section iv-f. yet, there are only 10 of them, by comparison to the 75 features used in [3]. so the conclusion here is that both extracting a directed graph and selecting a more appropriate set of features (in particular, topological measures able to handle edge weights) helped improve the performance. more importantly, the performance is greatly improved compared to our content-based approach [17], which is quite representative of the preprocessing and features used in the literature when classifying such data. this is a major result, as it shows that the sole structure of the conversation is enough to efficiently detect abuses, without considering at all the content of the exchanged messages. v. conclusion in this paper, we tackle the problem of automatic abuse detection in online communities. we propose to model online conversations through graphs, and to perform the classification task using only graph-based features. the method, while simple, yields good results (up to a 83.89 f-measure), besting the score obtained with a content-based approach [17] and our previous graph-based effort [3]. it completely ignores the content of messages exchanged between users of an online community, which means it is robust to intentional obfuscation of messages by abusive users, as well as unintentional content noise. it is also inherently language independent. one impor- tant limitation of our method is the high computational time required to extract the features. however, we show that it can be very significantly reduced by working with a small subset of relevant features, resulting in more than 97% of the original performance for less than 0.01 of the processing time. we also show that while our method is originally not designed for real-time abuse detection, the information available at the time the message appears is discriminative enough to do so. a straightforward extension of our work is to take advan- tage of both content- and graph-based features, an approach previously applied in other contexts [57]. in our case, they are both based on completely different types of information, so we can assume they are complementary, which could improve the classification performance. at the very least, it will be interesting to combine the features of the before graph with textual features since that can lead to a system useful for a prediction task. we also consider using a content-based classifier in a completely different ways, during the graph extraction process. such a classifier could be trained to detect the nature of the interaction between two users, allowing to extract a signed network (negative edge for a hostile exchange, positive otherwise). this additional information is likely to improve the performance of our graph-based classifier. finally, part of the future work will focus on applying our proposed approaches to other types of social network corpora. indeed, chat logs are a special case of communi- cations records that have a very specific structure (entan- glement of discussions, near-synchronous communications, various topics in a single flow of discussion, uncertainty about who is the intended recipient of a message...) which do not necessarily appear in other forms of social networks, such as forums or microblogs. for example, since our results have shown that directionality is not the dominant graph construction parameter, we would be interested in evaluating its impact on a type of social media integrating a clear response structure (i.e., a clear identification of who answers whom, such as in a forum like reddit or a tree-shaped comment section of a news website). in addition, another type of social network corpora might present a more distinct community structure and, therefore, render the meso-scale features we have presented more relevant. references [1] french republic. (2004). loi n2004-575 du 21 juin 2004 pour la confiance dans l'conomie numrique--article 6. [online]. available: https://www.legifrance.gouv.fr/affichtextearticle.do?idarticle= legiarti000023711900&cidtexte=legitext000005789847 [2] french republic. (1982). loi n82-65du 29 juillet 198sur la communication audiovisuelle--article 93-3. [online]. available: https://www.legifrance.gouv.fr/affichtextearticle.do?idarticle= legiarti000020740559&cidtexte=legitext000006068759 papegnies et al.: conversational networks for automatic online moderation 55 [3] e. papegnies, v. labatut, r. dufour, and g. linars, "graph-based features for automatic online abuse detection," in proc. int. conf. stat. lang. speech process. berlin, germany: springer, 2017, pp. 70--81. [4] e. spertus, "smokey: automatic recognition of hostile messages," in proc. 14th nat. conf. artif. intell. 9th conf. innov. appl. artif. intell. (aaai), 1997, pp. 1058--1065. [5] y. chen, y. zhou, s. zhu, and h. xu, "detecting offensive language in social media to protect adolescent online safety," in proc. ieee int. conf. privacy, secur., risk trust int. conf. social comput., sep. 2012, pp. 71--80. [6] k. dinakar, r. reichart, and h. lieberman, "modeling the detection of textual cyberbullying," in proc. 5th int. aaai conf. weblogs social media/workshop social mobile web, 2011, pp. 11--17. [7] v. s. chavan and s. s. shylaja, "machine learning approach for detection of cyber-aggressive comments by peers on social media network," in proc. ieee int. conf. adv. comput., commun. inform., aug. 2015, pp. 2354--2358. [8] h. mubarak, k. darwish, and w. magdy, "abusive language detection on arabic social media," in proc. 1st workshop abusive lang. online, 2017, pp. 52--56. [9] a. h. razavi, d. inkpen, s. uritsky, and s. matwin, "offensive language detection using multi-level classification," in proc. can. conf. artif. intell. berlin, germany: springer, 2010, pp. 16--27. [10] n. djuric, j. zhou, r. morris, m. grbovic, v. radosavljevic, and n. bhamidipati, "hate speech detection with comment embed- dings," in proc. acm 24th int. conf. world wide web, 2015, pp. 29--30. [11] j. h. park and p. fung, "one-step and two-step classification for abusive language detection on twitter," in proc. 1st workshop abusive lang. online, 2017, pp. 41--45. [12] j. pavlopoulos, p. malakasiotis, and i. androutsopoulos, "deep learning for user comment moderation," in proc. 1st workshop abusive lang. online, 2017, pp. 25--35. [13] h. hosseini, s. kannan, b. zhang, and r. poovendran. (2017). "deceiv- ing google's perspective api built for detecting toxic comments." [online]. available: https://arxiv.org/abs/1702.08138 [14] h. lee and a. y. ng, "spam deobfuscation using a hidden markov model," in proc. 2nd conf. email anti-spam, 2005, pp. 1--8. [15] s. rojas-galeano, "on obstructing obscenity obfuscation," acm trans. web, vol. 11, no. 2, p. 12, 2017. [16] d. yin, z. xue, l. hong, b. d. davison, a. kontostathis, and l. edwards, "detection of harassment on web 2.0," in proc. content anal. web, 2009, pp. 1--7 [17] e. papegnies, v. labatut, r. dufour, and g. linares, "impact of content features for automatic online abuse detection," in proc. int. conf. comput. linguistics intell. text process. berlin, germany: springer, 2017, pp. 404--419. [18] j. cheng, c. danescu-niculescu-mizil, and j. leskovec, "antisocial behavior in online discussion communities," in proc. int. aaai conf. web social media, 2015, pp. 61--70. [19] k. balci and a. a. salah, "automatic analysis and identification of verbal aggression and abusive behaviors for online social games," comput. hum. behav., vol. 53, pp. 517--526, dec. 2015. [20] p. mutton, "inferring and visualizing social networks on internet relay chat," in proc. ieee 8th int. conf. inf. vis., jul. 2004, pp. 35--43. [21] o. i. osesina, j. p. mcintire, p. r. havig, e. e. geiselman, c. bartley, and m. e. tudoreanu, "methods for extracting social network data from chatroom logs," proc. spie, vol. 8389, p. 83891h, jun. 201[online]. available: https://www.spiedigitallibrary.org/conferenceproceedings-of- spie/8389/83891h/methods-for-extracting-social-network-data-from- chatroom-logs/10.1117/12.920019.short?sso=1 [22] a. gruzd and c. haythornthwaite, "automated discovery and analysis of social networks from threaded discussions," in proc. int. netw. social netw. anal. conf., 2008. [online]. available: https://repository.arizona.edu/handle/10150/105081 [23] a. amtepe, m. s. krishnamoorthy, and b. yener, "a tool for internet chatroom surveillance," in proc. int. conf. intell. secur. inform. berlin, germany: springer, 2004, pp. 252--265. [24] m. forestier, j. velcin, and d. zighed, "extracting social networks to understand interaction," in proc. int. conf. adv. social netw. anal. mining, jul. 2011, pp. 213--219. [25] s. tavassoli, m. moessner, and k. a. zweig, "constructing social networks from semi-structured chat-log data," in proc. ieee/acm int. conf. adv. social netw. anal. mining, aug. 2014, pp. 146--149. [26] t. sinha and i. rajasingh, "investigating substructures in goal oriented online communities: case study of ubuntu irc," in proc. ieee int. adv. comput. conf., feb. 2014, pp. 916--922. [27] t. anwar and m. abulaish, "a social graph based text mining framework for chat log investigation," digit. invest., vol. 11, no. 4, pp. 349--362, 2014. [28] k. garimella, g. de francisci morales, a. gionis, and m. mathioudakis, "quantifying controversy on social media," in proc. 9th acm int. conf. web search data mining, 2015, pp. 33--42. [29] d. r. white and f. harary, "the cohesiveness of blocks in social networks: node connectivity and conditional density," sociol. methodol. banner, vol. 31, no. 1, pp. 305--359, 2001. [30] m. e. j. newman and m. girvan, "finding and evaluating community structure in networks," phys. rev. e, stat. phys. plasmas fluids relat. interdiscip. top., vol. 69, p. 026113, feb. 2004. [31] r. d. luce and a. d. perry, "a method of matrix analysis of group structure," psychometrika, vol. 14, no. 2, pp. 95--116, 1949. [32] s. wasserman and k. faust, social network analysis: methods and applications, vol. 8. cambridge, u.k.: cambridge univ. press, 1994, [33] m. e. j. newman, "assortative mixing in networks," phys. rev. lett., vol. 89, no. 20, p. 208701, oct. 2002. [34] p. bonacich, "factoring and weighting approaches to status scores and clique identification," j. math. sociol., vol. 2, no. 1, pp. 113--120, 1972. [35] j. m. kleinberg, "authoritative sources in a hyperlinked environment," j. acm , vol. 46, no. 5, pp. 604--632, 1999. [36] l. katz, "a new status index derived from sociometric analysis," psychometrika, vol. 18, no. 1, pp. 39--43, 1953. [37] p. bonacich, "power and centrality: a family of measures," amer. j. sociol., vol. 92, no. 5, pp. 1170--1182, 1987. [38] s. brin and l. page, "the anatomy of a large-scale hypertextual web search engine," comput. netw. isdn syst., vol. 30, nos. 1--7, pp. 107--117, apr. 1998. [39] e. estrada and j. a. rodrguez-velzquez, "subgraph centrality in complex networks," phys. rev. e, stat. phys. plasmas fluids relat. interdiscip. top., vol. 71, no. 5, p. 056103, 2005. [40] l. c. freeman, "a set of measures of centrality based on betweenness," sociometry, vol. 40, no. 1, pp. 35--41, mar. 1977. [41] a. bavelas, "communication patterns in task-oriented groups," j. acoust. soc. amer., vol. 22, no. 6, pp. 725--730, 1950. [42] f. harary, graph theory. reading, ma, usa: addison-wesley, 1969. [43] s. b. seidman, "network structure and minimum degree," social netw., vol. 5, no. 3, pp. 269--287, 1983. [44] r. guimer and l. a. n. amaral, "functional cartography of complex metabolic networks," nature, vol. 433, pp. 895--900, feb. 2005. [45] v. labatut, n. dugu, and a. perez, "identifying the community roles of social capitalists in the twitter network," in proc. ieee/acm int. conf. adv. social netw. anal. mining, aug. 2014, pp. 371--374. [46] m. e. shaw, "group structure and the behavior of individuals in small groups," j. psychol., vol. 38, no. 1, pp. 139--149, 1954. [47] a. barrat, m. barthlemy, r. pastor-satorras, and a. vespignani, "the architecture of complex weighted networks," proc. nat. acad. sci. usa, vol. 101, no. 11, pp. 3747--3752, mar. 2004. [48] d. j. watts and s. h. strogatz, "collective dynamics of `small-world' networks," nature, vol. 393, no. 6684, pp. 440--442, 1998. [49] r. s. burt, "structural holes and good ideas1," amer. j. sociol., vol. 110, no. 2, pp. 349--399, 2004. [50] l. c. freeman, "centrality in social networks conceptual clarification," social netw., vol. 1, no. 3, pp. 215--239, 1979. [51] p. bonacich and p. lloyd, "eigenvector-like measures of centrality for asymmetric relations," social netw., vol. 23, no. 3, pp. 191--201, 2001. [52] m. rosvall and c. t. bergstrom, "maps of random walks on complex networks reveal community structure," proc. nat. acad. sci. usa, vol. 105, no. 4, pp. 1118--1123, 2008. [53] n. dugu, v. labatut, and a. perez, "a community role approach to assess social capitalists visibility in the twitter network," social netw. anal. mining, vol. 5, p. 26, dec. 2015. [54] g. csardi and t. nepusz, "the igraph software package for complex network research," inter j. complex syst., vol. 1695, no. 5, pp. 1--9, 2006. [online]. available: http://www.interjournal. org/manuscript_abstract.php?361100992 [55] f. pedregosa et al., "scikit-learn: machine learning in python," j. mach. learn. res., vol. 12, pp. 2825--2830, oct. 2011. [56] p. j. rousseeuw, "silhouettes: a graphical aid to the interpretation and validation of cluster analysis," j. comput. appl. math., vol. 20, no. 1, pp. 53--65, 1987. [57] a. rumshisky et al., "combining network and language indicators for tracking conflict intensity," in proc. int. conf. social inform. berlin, germany: springer, 2017, pp. 391--404. </introduction>
    <corps></corps>
    <conclusion></conclusion>
	<discussion>except when sarcasm is used. it is worth noting that sarcasm
can be considered as a form of natural language obfuscation
that is especially hard to detect in written communications,
because of the lack of inflection clues.
chavan and shylaja [7] review machine learning (ml)
approaches to detect cyberbullying in online social networks.
they show that pronoun occurrences, usually neglected in text
classification, are very important to detect online bullying.
they use skip-gram features to mitigate the sentence-level
context issues by taking into account distant words. these
new features allow them to boost the accuracy of a classifier
detecting bullying by 4% points. the approach is, however,
still vulnerable to involuntary misspellings and word-level
obfuscation. it uses a language-dependent list of badwords
during preprocessing.
in their recent article, mubarak et al. [8] work on the
detection of offensive language in arabic media, by intro-
ducing the interesting possibility of dynamically generating
and expanding a list of bad words. they extract a corpus of
tweets that is divided into two classes (obscene/not obscene)
based on static rules. then, they perform a log odds ratio
analysis to detect the words favoring documents from the
obscene class. such an approach could be very useful in an
online classification setting, but inherently requires a dataset
where the number of samples in the obscene class is large.
still, they show that a list of words dynamically generated
using that method contains 60% of new obscene words, and
the process can be iterated over. relatively to our problem
of interest, the main limitation of this paper is its focus on
obscene words, which are just one specific type of abuse.
razavi et al. [9] focus on a wider spectrum of types of abuse
than the previously cited works, which they call inflammatory
comments. it ranges from impoliteness to insult, and includes
rants and taunts. to detect them, they stack three levels of
naive bayes classifier variants, fed with features related to
the presence, frequency, and strength of offensive expressions.
these are computed based on a manually constituted lexicon
of offensive expressions and insults, which makes the method
relatively corpus-specific. the resulting system shows high
40 ieee transactions on computational social systems, vol. 6, no. 1, february 2019
precision and has the useful characteristics of being updatable
online. it is, however, vulnerable to the text-based obfuscation
techniques we have previously mentioned.
with recent developments in gpu architecture and hardware
availability, more computationally expansive techniques have
been used. djuric et al. [10] detect hate speech in twitter
data. they adopt a two-step approach consisting in first
learning a low-dimensional representation of the tweets, and
then applying a classifier to discriminate them based on this
representation. they note that jointly using message- and
word embeddings instead of simple bag-of-words boosts the
performance. park and fung [11] also work on tweets using
neural networks, but they focus only on sexism- and racism-
related cases. they propose a two-step framework consisting
in first training a convolutional neural network (cnn) to
identify the absence/presence of abuse, and then performing
a simple logistic regression to further discriminate between
sexism and racism. both of these approaches are inherently
portable, however, they require a lot of data.
pavlopoulos et al. [12] develop an automatic moderation
system for comments posted by users on websites. it is based
on a recurrent neural network operating on word embeddings,
with an attention mechanism. they apply it to two large
corpus extracted from a greek sports website and the english
wikipedia. the proposed system outperforms cnn and other
more mainstream classifiers. however, it is worth noticing that
these tasks are slightly different, as the the greek corpus is
annotated for general moderation, whereas the english one
focuses on personal attacks.
it is worth noting that all these ml-based approaches
perform better when a large dataset is available for train-
ing. however, text-based approaches are usually language
dependent, which means that models have to be trained on
a dataset of the specific language. this is usually not an issue
when classifying english messages because of the wealth of
publicly available data but is problematic in our case, since
our messages come from low-resource language communities.
content-based text classification usually makes for a good
baseline. however, such methods have severe limitations. first,
abuse can be spread over a succession of messages. some
messages can even reference a shared history between two
users. second, it is very common for users to voluntarily
obfuscate message content to work around badwords detection.
indeed, abusers can bypass automatic systems by making
the abusive content difficult to detect: for instance, they can
intentionally modify the spelling of a forbidden word.
hosseini et al. [13] demonstrate such an attack against
the google perspective api.2 adversarial attacks based on
word-level obfuscation are nothing new, and approaches exist
to counter them. for instance, lee and ng [14] experiment
with spam de-obfuscation using a hidden markov model that
incorporates lexical information. such an approach yields good
results for de-obfuscation, but it is computationally expen-
sive and requires a dataset of obfuscated words for training.
more recently, rojas-galeano [15] describes a more compact
approach based on a dynamic programing sequence alignment
2https://www.perspectiveapi.com
algorithm. it has a different set of limitations, the main one
being that it does not allow for one character to be used as
an obfuscated version of several distinct original characters (it
uses a one-to-one character mapping).
2) context-based approaches: because the reactions of
other users to an abuse case are completely beyond the control
of the abuser, some works consider the content of messages
around the targeted message, instead of the content of the
targeted message only.
for instance, yin et al. [16] use features derived from the
sentences neighboring a given message to detect harassment
on the web. harassment implies repetition and can be con-
sidered as a specific type of abuse. their goal is to spot
conversations going off-topic and use that as an indicator.</discussion>
	<biblio>[1] french republic. (2004). loi n2004-575 du 21 juin 2004 pour la
confiance dans l'conomie numrique--article 6. [online]. available:
https://www.legifrance.gouv.fr/affichtextearticle.do?idarticle=
legiarti000023711900&cidtexte=legitext000005789847
[2] french republic. (1982). loi n82-652 du 29 juillet 1982 sur la
communication audiovisuelle--article 93-3. [online]. available:
https://www.legifrance.gouv.fr/affichtextearticle.do?idarticle=
legiarti000020740559&cidtexte=legitext000006068759
papegnies et al.: conversational networks for automatic online moderation 55
[3] e. papegnies, v. labatut, r. dufour, and g. linars, "graph-based
features for automatic online abuse detection," in proc. int. conf. stat.
lang. speech process. berlin, germany: springer, 2017, pp. 70--81.
[4] e. spertus, "smokey: automatic recognition of hostile messages,"
in proc. 14th nat. conf. artif. intell. 9th conf. innov. appl. artif.
intell. (aaai), 1997, pp. 1058--1065.
[5] y. chen, y. zhou, s. zhu, and h. xu, "detecting offensive language
in social media to protect adolescent online safety," in proc. ieee int.
conf. privacy, secur., risk trust int. conf. social comput., sep. 2012,
pp. 71--80.
[6] k. dinakar, r. reichart, and h. lieberman, "modeling the detection
of textual cyberbullying," in proc. 5th int. aaai conf. weblogs social
media/workshop social mobile web, 2011, pp. 11--17.
[7] v. s. chavan and s. s. shylaja, "machine learning approach for detection
of cyber-aggressive comments by peers on social media network," in
proc. ieee int. conf. adv. comput., commun. inform., aug. 2015,
pp. 2354--2358.
[8] h. mubarak, k. darwish, and w. magdy, "abusive language detection
on arabic social media," in proc. 1st workshop abusive lang. online,
2017, pp. 52--56.
[9] a. h. razavi, d. inkpen, s. uritsky, and s. matwin, "offensive language
detection using multi-level classification," in proc. can. conf. artif.
intell. berlin, germany: springer, 2010, pp. 16--27.
[10] n. djuric, j. zhou, r. morris, m. grbovic, v. radosavljevic, and
n. bhamidipati, "hate speech detection with comment embed-
dings," in proc. acm 24th int. conf. world wide web, 2015,
pp. 29--30.
[11] j. h. park and p. fung, "one-step and two-step classification for abusive
language detection on twitter," in proc. 1st workshop abusive lang.
online, 2017, pp. 41--45.
[12] j. pavlopoulos, p. malakasiotis, and i. androutsopoulos, "deep learning
for user comment moderation," in proc. 1st workshop abusive lang.
online, 2017, pp. 25--35.
[13] h. hosseini, s. kannan, b. zhang, and r. poovendran. (2017). "deceiv-
ing google's perspective api built for detecting toxic comments."
[online]. available: https://arxiv.org/abs/1702.08138
[14] h. lee and a. y. ng, "spam deobfuscation using a hidden markov
model," in proc. 2nd conf. email anti-spam, 2005, pp. 1--8.
[15] s. rojas-galeano, "on obstructing obscenity obfuscation," acm trans.
web, vol. 11, no. 2, p. 12, 2017.
[16] d. yin, z. xue, l. hong, b. d. davison, a. kontostathis, and
l. edwards, "detection of harassment on web 2.0," in proc. content
anal. web, 2009, pp. 1--7
[17] e. papegnies, v. labatut, r. dufour, and g. linares, "impact of content
features for automatic online abuse detection," in proc. int. conf.
comput. linguistics intell. text process. berlin, germany: springer,
2017, pp. 404--419.
[18] j. cheng, c. danescu-niculescu-mizil, and j. leskovec, "antisocial
behavior in online discussion communities," in proc. int. aaai conf.
web social media, 2015, pp. 61--70.
[19] k. balci and a. a. salah, "automatic analysis and identification of
verbal aggression and abusive behaviors for online social games,"
comput. hum. behav., vol. 53, pp. 517--526, dec. 2015.
[20] p. mutton, "inferring and visualizing social networks on internet
relay chat," in proc. ieee 8th int. conf. inf. vis., jul. 2004,
pp. 35--43.
[21] o. i. osesina, j. p. mcintire, p. r. havig, e. e. geiselman, c. bartley,
and m. e. tudoreanu, "methods for extracting social network data from
chatroom logs," proc. spie, vol. 8389, p. 83891h, jun. 2012. [online].
available: https://www.spiedigitallibrary.org/conferenceproceedings-of-
spie/8389/83891h/methods-for-extracting-social-network-data-from-
chatroom-logs/10.1117/12.920019.short?sso=1
[22] a. gruzd and c. haythornthwaite, "automated discovery and
analysis of social networks from threaded discussions," in proc.
int. netw. social netw. anal. conf., 2008. [online]. available:
https://repository.arizona.edu/handle/10150/105081
[23] a. amtepe, m. s. krishnamoorthy, and b. yener, "a tool for internet
chatroom surveillance," in proc. int. conf. intell. secur. inform. berlin,
germany: springer, 2004, pp. 252--265.
[24] m. forestier, j. velcin, and d. zighed, "extracting social networks
to understand interaction," in proc. int. conf. adv. social netw. anal.
mining, jul. 2011, pp. 213--219.
[25] s. tavassoli, m. moessner, and k. a. zweig, "constructing social
networks from semi-structured chat-log data," in proc. ieee/acm int.
conf. adv. social netw. anal. mining, aug. 2014, pp. 146--149.
[26] t. sinha and i. rajasingh, "investigating substructures in goal oriented
online communities: case study of ubuntu irc," in proc. ieee int.
adv. comput. conf., feb. 2014, pp. 916--922.
[27] t. anwar and m. abulaish, "a social graph based text mining framework
for chat log investigation," digit. invest., vol. 11, no. 4, pp. 349--362,
2014.
[28] k. garimella, g. de francisci morales, a. gionis, and m. mathioudakis,
"quantifying controversy on social media," in proc. 9th acm int. conf.
web search data mining, 2015, pp. 33--42.
[29] d. r. white and f. harary, "the cohesiveness of blocks in social
networks: node connectivity and conditional density," sociol. methodol.
banner, vol. 31, no. 1, pp. 305--359, 2001.
[30] m. e. j. newman and m. girvan, "finding and evaluating community
structure in networks," phys. rev. e, stat. phys. plasmas fluids relat.
interdiscip. top., vol. 69, p. 026113, feb. 2004.
[31] r. d. luce and a. d. perry, "a method of matrix analysis of group
structure," psychometrika, vol. 14, no. 2, pp. 95--116, 1949.
[32] s. wasserman and k. faust, social network analysis: methods
and applications, vol. 8. cambridge, u.k.: cambridge univ. press,
1994,
[33] m. e. j. newman, "assortative mixing in networks," phys. rev. lett.,
vol. 89, no. 20, p. 208701, oct. 2002.
[34] p. bonacich, "factoring and weighting approaches to status scores and
clique identification," j. math. sociol., vol. 2, no. 1, pp. 113--120, 1972.
[35] j. m. kleinberg, "authoritative sources in a hyperlinked environment,"
j. acm , vol. 46, no. 5, pp. 604--632, 1999.
[36] l. katz, "a new status index derived from sociometric analysis,"
psychometrika, vol. 18, no. 1, pp. 39--43, 1953.
[37] p. bonacich, "power and centrality: a family of measures," amer.
j. sociol., vol. 92, no. 5, pp. 1170--1182, 1987.
[38] s. brin and l. page, "the anatomy of a large-scale hypertextual
web search engine," comput. netw. isdn syst., vol. 30, nos. 1--7,
pp. 107--117, apr. 1998.
[39] e. estrada and j. a. rodrguez-velzquez, "subgraph centrality in
complex networks," phys. rev. e, stat. phys. plasmas fluids relat.
interdiscip. top., vol. 71, no. 5, p. 056103, 2005.
[40] l. c. freeman, "a set of measures of centrality based on betweenness,"
sociometry, vol. 40, no. 1, pp. 35--41, mar. 1977.
[41] a. bavelas, "communication patterns in task-oriented groups,"
j. acoust. soc. amer., vol. 22, no. 6, pp. 725--730, 1950.
[42] f. harary, graph theory. reading, ma, usa: addison-wesley, 1969.
[43] s. b. seidman, "network structure and minimum degree," social netw.,
vol. 5, no. 3, pp. 269--287, 1983.
[44] r. guimer and l. a. n. amaral, "functional cartography of
complex metabolic networks," nature, vol. 433, pp. 895--900,
feb. 2005.
[45] v. labatut, n. dugu, and a. perez, "identifying the community roles
of social capitalists in the twitter network," in proc. ieee/acm int.
conf. adv. social netw. anal. mining, aug. 2014, pp. 371--374.
[46] m. e. shaw, "group structure and the behavior of individuals in small
groups," j. psychol., vol. 38, no. 1, pp. 139--149, 1954.
[47] a. barrat, m. barthlemy, r. pastor-satorras, and a. vespignani,
"the architecture of complex weighted networks," proc. nat. acad. sci.
usa, vol. 101, no. 11, pp. 3747--3752, mar. 2004.
[48] d. j. watts and s. h. strogatz, "collective dynamics of `small-world'
networks," nature, vol. 393, no. 6684, pp. 440--442, 1998.
[49] r. s. burt, "structural holes and good ideas1," amer. j. sociol., vol. 110,
no. 2, pp. 349--399, 2004.
[50] l. c. freeman, "centrality in social networks conceptual clarification,"
social netw., vol. 1, no. 3, pp. 215--239, 1979.
[51] p. bonacich and p. lloyd, "eigenvector-like measures of centrality
for asymmetric relations," social netw., vol. 23, no. 3, pp. 191--201,
2001.
[52] m. rosvall and c. t. bergstrom, "maps of random walks on complex
networks reveal community structure," proc. nat. acad. sci. usa,
vol. 105, no. 4, pp. 1118--1123, 2008.
[53] n. dugu, v. labatut, and a. perez, "a community role approach to
assess social capitalists visibility in the twitter network," social netw.
anal. mining, vol. 5, p. 26, dec. 2015.
[54] g. csardi and t. nepusz, "the igraph software package for
complex network research," inter j. complex syst., vol. 1695,
no. 5, pp. 1--9, 2006. [online]. available: http://www.interjournal.
org/manuscript_abstract.php?361100992
[55] f. pedregosa et al., "scikit-learn: machine learning in python," j. mach.
learn. res., vol. 12, pp. 2825--2830, oct. 2011.
[56] p. j. rousseeuw, "silhouettes: a graphical aid to the interpretation and
validation of cluster analysis," j. comput. appl. math., vol. 20, no. 1,
pp. 53--65, 1987.
[57] a. rumshisky et al., "combining network and language indicators for
tracking conflict intensity," in proc. int. conf. social inform. berlin,</biblio>
</article>